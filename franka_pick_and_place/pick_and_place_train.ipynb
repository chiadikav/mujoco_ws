{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfb44978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠ Virtual environment not found at /home/cvincen6/mujoco_ws/venv\n",
      "Currently using Python: /home/cvincen6/mujoco_ws/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Activate virtual environment\n",
    "venv_path = os.path.expanduser(\"~/mujoco_ws/venv\")\n",
    "if os.path.exists(venv_path):\n",
    "    sys.path.insert(0, os.path.join(venv_path, \"lib\", \"python3.11\", \"site-packages\"))\n",
    "    print(f\"✓ Virtual environment activated: {venv_path}\")\n",
    "    print(f\"✓ Python executable: {sys.executable}\")\n",
    "else:\n",
    "    print(f\"⚠ Virtual environment not found at {venv_path}\")\n",
    "    print(f\"Currently using Python: {sys.executable}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de253074",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "464c49dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch using: cuda device\n",
      "NumPy version: 2.4.1\n",
      "MuJoCo version: 3.4.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mujoco\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "import time\n",
    "import torch\n",
    "from datetime import timedelta\n",
    "import os\n",
    "\n",
    "print(f\"PyTorch using: {'cuda' if torch.cuda.is_available() else 'cpu'} device\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"MuJoCo version: {mujoco.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5c5d72",
   "metadata": {},
   "source": [
    "## Environment: Touch the Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9d4d7711",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PickPlaceEnv(gym.Env):\n",
    "    \"\"\"Franka Panda gripper environment (inspired by panda-gym).\n",
    "    \n",
    "    Key improvements:\n",
    "    - Uses joint position control with incremental targets (like panda-gym)\n",
    "    - Limits action to 0.05 rad/step for smooth, learnable control\n",
    "    - Observation includes gripper width (not individual fingers)\n",
    "    - Uses proper neutral pose and joint limit awareness\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_path='model/pick_place_scene.xml', render_mode=None):\n",
    "        super().__init__()\n",
    "        self.render_mode = render_mode\n",
    "        self.viewer = None\n",
    "        \n",
    "        # Load model\n",
    "        try:\n",
    "            self.model = mujoco.MjModel.from_xml_path(model_path)\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"Model not found at {model_path}\")\n",
    "        \n",
    "        self.data = mujoco.MjData(self.model)\n",
    "        self.dt = self.model.opt.timestep\n",
    "        \n",
    "        # Franka Panda configuration (7 arm joints + 2 gripper fingers)\n",
    "        self.arm_joint_indices = np.array([0, 1, 2, 3, 4, 5, 6])\n",
    "        self.gripper_joint_indices = np.array([7, 8])\n",
    "        \n",
    "        # Joint forces (from panda-gym reference)\n",
    "        self.joint_forces = np.array([87.0, 87.0, 87.0, 87.0, 12.0, 120.0, 120.0, 170.0, 170.0])\n",
    "        \n",
    "        # Neutral pose (from panda-gym)\n",
    "        self.neutral_joint_values = np.array([0.00, 0.41, 0.00, -1.85, 0.00, 2.26, 0.79, 0.04, 0.04])\n",
    "        \n",
    "        # Action space: 7 arm joints + 1 gripper (incremental control [-1, 1])\n",
    "        self.action_space = spaces.Box(\n",
    "            low=np.array([-1.0]*8),\n",
    "            high=np.array([1.0]*8),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # Observation space: EE position (3) + EE velocity (3) + gripper width (1) + box position (3) = 10D\n",
    "        # Simplified observation like panda-gym\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf, shape=(10,), dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        self.max_episode_steps = 500\n",
    "        self.step_count = 0\n",
    "        self.active_box = None\n",
    "        \n",
    "        # Hand/gripper link index\n",
    "        self.hand_id = self.model.body('hand').id\n",
    "        self.max_action_step = 0.05  # Limit control to 0.05 rad per step (like panda-gym)\n",
    "    \n",
    "    def _get_obs(self):\n",
    "        \"\"\"Get observation: EE position/velocity + gripper width + box position.\"\"\"\n",
    "        # End effector (hand body) position and velocity\n",
    "        ee_pos = self.data.body(self.hand_id).xpos.copy()\n",
    "        ee_vel = self.data.body(self.hand_id).cvel[:3].copy()  # Linear velocity\n",
    "        \n",
    "        # Gripper width (sum of both finger angles)\n",
    "        gripper_width = self.data.qpos[7] + self.data.qpos[8]\n",
    "        \n",
    "        # Target box position\n",
    "        box_pos = self.data.body(self.active_box).xpos.copy()\n",
    "        \n",
    "        obs = np.concatenate([\n",
    "            ee_pos, ee_vel, [gripper_width], box_pos\n",
    "        ]).astype(np.float32)\n",
    "        \n",
    "        return obs\n",
    "    \n",
    "    def reset(self, seed=None, options=None):\n",
    "        \"\"\"Reset environment to neutral pose with random box.\"\"\"\n",
    "        super().reset(seed=seed)\n",
    "        mujoco.mj_resetData(self.model, self.data)\n",
    "        \n",
    "        # Set to neutral pose\n",
    "        self.data.qpos[:len(self.neutral_joint_values)] = self.neutral_joint_values\n",
    "        \n",
    "        # Randomly select target box\n",
    "        all_boxes = [\n",
    "            'red_box_0', 'red_box_1', 'red_box_2',\n",
    "            'blue_box_0', 'blue_box_1', 'blue_box_2',\n",
    "            'green_box_0', 'green_box_1', 'green_box_2',\n",
    "            'yellow_box_0', 'yellow_box_1', 'yellow_box_2'\n",
    "        ]\n",
    "        self.active_box = np.random.choice(all_boxes)\n",
    "        self.step_count = 0\n",
    "        \n",
    "        # Settle physics\n",
    "        for _ in range(10):\n",
    "            mujoco.mj_step(self.model, self.data)\n",
    "        \n",
    "        obs = self._get_obs()\n",
    "        return obs, {}\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"Execute action: controlled descent from above with limited velocity.\"\"\"\n",
    "        action = np.clip(action, -1.0, 1.0)\n",
    "        \n",
    "        # Get current state\n",
    "        ee_pos = self.data.body(self.hand_id).xpos.copy()\n",
    "        box_pos = self.data.body(self.active_box).xpos.copy()\n",
    "        \n",
    "        # Current arm angles\n",
    "        current_arm_angles = self.data.qpos[self.arm_joint_indices].copy()\n",
    "        \n",
    "        # Target: directly above box at safe height\n",
    "        approach_height = box_pos[2] + 0.10  # 10cm above box to start approach\n",
    "        target_xyz = np.array([box_pos[0], box_pos[1], approach_height])\n",
    "        \n",
    "        # Calculate errors\n",
    "        pos_error = target_xyz - ee_pos\n",
    "        horiz_error = np.linalg.norm(pos_error[:2])\n",
    "        vert_error = pos_error[2]\n",
    "        \n",
    "        # Arm control based on distance to approach position\n",
    "        if horiz_error > 0.02 or vert_error > 0.02:  # Still far from target\n",
    "            # Scale toward target with action influence\n",
    "            arm_ctrl = action[:7] * self.max_action_step * 0.4  # Reduced speed toward target\n",
    "        else:\n",
    "            # Close to target, very fine control\n",
    "            arm_ctrl = action[:7] * self.max_action_step * 0.2  # Very slow fine motion\n",
    "        \n",
    "        target_arm_angles = current_arm_angles + arm_ctrl\n",
    "        \n",
    "        # Gripper control: slower, more controlled\n",
    "        gripper_ctrl = action[7] * 0.01  # Very slow gripper (1cm per step max)\n",
    "        current_gripper_width = self.data.qpos[7] + self.data.qpos[8]\n",
    "        target_gripper_width = current_gripper_width + gripper_ctrl\n",
    "        target_gripper_width = np.clip(target_gripper_width, 0, 0.04)\n",
    "        \n",
    "        # Combine target angles\n",
    "        target_angles = np.concatenate([\n",
    "            target_arm_angles,\n",
    "            [target_gripper_width / 2, target_gripper_width / 2]\n",
    "        ])\n",
    "        \n",
    "        # Control with adaptive damping based on proximity to target\n",
    "        is_near_target = horiz_error < 0.05 and vert_error < 0.05\n",
    "        self._control_joints(target_angles, slow_descent=is_near_target)\n",
    "        \n",
    "        # More substeps for smoother motion\n",
    "        num_substeps = 15 if is_near_target else 10\n",
    "        for _ in range(num_substeps):\n",
    "            mujoco.mj_step(self.model, self.data)\n",
    "        \n",
    "        self.step_count += 1\n",
    "        obs = self._get_obs()\n",
    "        \n",
    "        # Compute reward\n",
    "        ee_pos_new = self.data.body(self.hand_id).xpos.copy()\n",
    "        box_pos = self.data.body(self.active_box).xpos.copy()\n",
    "        \n",
    "        # Reward for approaching from above (xy alignment)\n",
    "        horiz_dist = np.linalg.norm(ee_pos_new[:2] - box_pos[:2])\n",
    "        vert_dist = ee_pos_new[2] - box_pos[2]\n",
    "        \n",
    "        reward = 0.0\n",
    "        \n",
    "        # Phase 1: Horizontal alignment (xy plane)\n",
    "        if horiz_dist < 0.15:\n",
    "            reward += 30.0 * max(0, 1.0 - horiz_dist / 0.15)\n",
    "        \n",
    "        # Phase 2: Vertical approach from above\n",
    "        if horiz_dist < 0.08 and vert_dist > -0.02:  # Close horizontally and above box\n",
    "            reward += 40.0 * max(0, 1.0 - (vert_dist - 0.06) / 0.06)\n",
    "        \n",
    "        # Touch reward: gentle contact with box top\n",
    "        touch_dist = np.linalg.norm(ee_pos_new - box_pos)\n",
    "        if touch_dist < 0.10:  # Close enough to touch\n",
    "            reward += 100.0 * max(0, 1.0 - touch_dist / 0.10)\n",
    "            # Bonus for coming from above (positive z trajectory)\n",
    "            if vert_dist < 0.02:\n",
    "                reward += 50.0\n",
    "        \n",
    "        # Penalize high joint velocities to discourage slamming\n",
    "        joint_vel_penalty = -np.linalg.norm(self.data.qvel[:7]) * 0.005\n",
    "        reward += joint_vel_penalty\n",
    "        \n",
    "        # Time penalty\n",
    "        reward -= 0.0003\n",
    "        \n",
    "        terminated = self.step_count >= self.max_episode_steps\n",
    "        \n",
    "        return obs, reward, terminated, False, {}\n",
    "    \n",
    "    def _control_joints(self, target_angles, slow_descent=False):\n",
    "        \"\"\"Control joints using PD control with adaptive gains for smooth motion.\"\"\"\n",
    "        # Proportional and derivative gains (reduced during descent for smoother control)\n",
    "        kp = 80.0 if slow_descent else 100.0  # Lower gain during descent\n",
    "        kd = 15.0 if slow_descent else 10.0   # Higher damping for smoother descent\n",
    "        \n",
    "        # For arm joints (0-6): use PD control\n",
    "        for i in range(7):\n",
    "            current_angle = self.data.qpos[i]\n",
    "            error = target_angles[i] - current_angle\n",
    "            \n",
    "            ctrl = kp * error\n",
    "            \n",
    "            vel = self.data.qvel[i]\n",
    "            ctrl -= kd * vel\n",
    "            \n",
    "            # Clip to force limit\n",
    "            force_limit = self.joint_forces[i]\n",
    "            ctrl = np.clip(ctrl, -force_limit, force_limit)\n",
    "            \n",
    "            self.data.ctrl[i] = ctrl\n",
    "        \n",
    "        # For gripper (control index 7 maps to gripper tendon)\n",
    "        gripper_width_cmd = target_angles[7] * target_angles[8]\n",
    "        gripper_ctrl = int((gripper_width_cmd / 0.04) * 255)\n",
    "        gripper_ctrl = np.clip(gripper_ctrl, 0, 255)\n",
    "        self.data.ctrl[7] = gripper_ctrl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce90125f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ train_pick_place() function defined\n"
     ]
    }
   ],
   "source": [
    "def train_pick_place(total_timesteps=100000):\n",
    "    \"\"\"Train Franka Panda gripper to touch randomly placed boxes (improved control).\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"Training: Touch the randomly placed box (panda-gym style control)\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Task: Train gripper to reach and touch one randomly placed box\")\n",
    "    print(f\"Improvement: Incremental joint position control (0.05 rad/step max)\")\n",
    "    print(f\"Device: {('CUDA' if torch.cuda.is_available() else 'CPU')}\")\n",
    "    print()\n",
    "    \n",
    "    # Create environment\n",
    "    env = make_vec_env(\n",
    "        lambda: PickPlaceEnv(model_path='model/pick_place_scene.xml'),\n",
    "        n_envs=4\n",
    "    )\n",
    "    \n",
    "    # Train with PPO\n",
    "    model = PPO(\n",
    "        \"MlpPolicy\",\n",
    "        env,\n",
    "        learning_rate=3e-4,\n",
    "        n_steps=1024,\n",
    "        batch_size=64,\n",
    "        n_epochs=20,\n",
    "        gamma=0.99,\n",
    "        gae_lambda=0.95,\n",
    "        clip_range=0.2,\n",
    "        verbose=1,\n",
    "        policy_kwargs={\"net_arch\": [256, 256]}\n",
    "    )\n",
    "    \n",
    "    print(f\"Training for {total_timesteps:,} timesteps...\\n\")\n",
    "    start_time = time.time()\n",
    "    model.learn(total_timesteps=total_timesteps)\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    model.save(\"touch_box_ppo\")\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"✓ Training complete! ({elapsed/60:.1f} minutes)\")\n",
    "    print(f\"✓ Model saved as 'touch_box_ppo'\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    env.close()\n",
    "    return model\n",
    "\n",
    "print(\"✓ train_pick_place() function defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "383d7385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Training: Touch the randomly placed box\n",
      "======================================================================\n",
      "Task: Train gripper to reach and touch one randomly placed box\n",
      "Reward: +1.0 * (1 - distance/0.5) for reaching, +10.0 for touching\n",
      "Device: CUDA\n",
      "\n",
      "Using cuda device\n",
      "Training for 400,000 timesteps...\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -4.13    |\n",
      "| time/              |          |\n",
      "|    fps             | 1198     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 4096     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 126         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 862         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007148965 |\n",
      "|    clip_fraction        | 0.0751      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.4       |\n",
      "|    explained_variance   | -4.62       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0178     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00659    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00328     |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 500           |\n",
      "|    ep_rew_mean          | 156           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 788           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 15            |\n",
      "|    total_timesteps      | 12288         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041911786 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -11.4         |\n",
      "|    explained_variance   | 0.000247      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 816           |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.00106      |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 1.83e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 500           |\n",
      "|    ep_rew_mean          | 116           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 762           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 21            |\n",
      "|    total_timesteps      | 16384         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046641947 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -11.4         |\n",
      "|    explained_variance   | 0.587         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 63.3          |\n",
      "|    n_updates            | 60            |\n",
      "|    policy_gradient_loss | -0.00123      |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 213           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 95.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 736          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060749697 |\n",
      "|    clip_fraction        | 0.0262       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -11.4        |\n",
      "|    explained_variance   | 0.893        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.3          |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00637     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 25.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 83.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 727         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009839353 |\n",
      "|    clip_fraction        | 0.0929      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.4       |\n",
      "|    explained_variance   | 0.673       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.03        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00816    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 19          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 75.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 719         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010045052 |\n",
      "|    clip_fraction        | 0.0819      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.4       |\n",
      "|    explained_variance   | 0.697       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00658    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 32.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 85          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 715         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013921028 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.4       |\n",
      "|    explained_variance   | 0.45        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00679    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 190         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 712         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009130258 |\n",
      "|    clip_fraction        | 0.0661      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.4       |\n",
      "|    explained_variance   | 0.646       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00563    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 199         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 218          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 709          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 57           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048240246 |\n",
      "|    clip_fraction        | 0.0209       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -11.3        |\n",
      "|    explained_variance   | 0.215        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.75e+03     |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00509     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 5.98e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 235         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 708         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009378318 |\n",
      "|    clip_fraction        | 0.0648      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.4       |\n",
      "|    explained_variance   | 0.705       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.48e+03    |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00765    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 2.11e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 217          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 703          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 69           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051506106 |\n",
      "|    clip_fraction        | 0.0313       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -11.4        |\n",
      "|    explained_variance   | 0.798        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 319          |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00538     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 712          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 218         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 702         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011793249 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.3       |\n",
      "|    explained_variance   | 0.879       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.52        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00237    |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 53.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 211          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 700          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 81           |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068365457 |\n",
      "|    clip_fraction        | 0.0419       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -11.3        |\n",
      "|    explained_variance   | 0.915        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 130          |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00527     |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 143          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 219         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 700         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008759365 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.3       |\n",
      "|    explained_variance   | 0.501       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 57.2        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00664    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 252         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 500        |\n",
      "|    ep_rew_mean          | 214        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 697        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 93         |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00930649 |\n",
      "|    clip_fraction        | 0.0761     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -11.3      |\n",
      "|    explained_variance   | 0.81       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 45.3       |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.00711   |\n",
      "|    std                  | 0.999      |\n",
      "|    value_loss           | 499        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 215         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 696         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012586792 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.3       |\n",
      "|    explained_variance   | 0.856       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.11        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 14          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 217         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 695         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 105         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010677595 |\n",
      "|    clip_fraction        | 0.0998      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.3       |\n",
      "|    explained_variance   | 0.831       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 48.5        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00876    |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 51.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 221         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 692         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007347161 |\n",
      "|    clip_fraction        | 0.0661      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.3       |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00545    |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 55.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 472          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 691          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 118          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021550588 |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -11.3        |\n",
      "|    explained_variance   | 0.247        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.77e+03     |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 2.54e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 501          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 690          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 124          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059807245 |\n",
      "|    clip_fraction        | 0.0279       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -11.3        |\n",
      "|    explained_variance   | 0.439        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.26e+03     |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.0056      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 1.36e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 524         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 689         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 130         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007324551 |\n",
      "|    clip_fraction        | 0.0466      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.3       |\n",
      "|    explained_variance   | 0.712       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.79e+03    |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    std                  | 0.994       |\n",
      "|    value_loss           | 1.4e+04     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 583         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 688         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008072643 |\n",
      "|    clip_fraction        | 0.052       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.3       |\n",
      "|    explained_variance   | 0.821       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 203         |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00664    |\n",
      "|    std                  | 0.988       |\n",
      "|    value_loss           | 5.09e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 623         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 687         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007826496 |\n",
      "|    clip_fraction        | 0.0594      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.3       |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.27e+03    |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0068     |\n",
      "|    std                  | 0.993       |\n",
      "|    value_loss           | 1.16e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 634          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 687          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 148          |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076418035 |\n",
      "|    clip_fraction        | 0.0569       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -11.2        |\n",
      "|    explained_variance   | 0.904        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.19e+03     |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00578     |\n",
      "|    std                  | 0.984        |\n",
      "|    value_loss           | 2.64e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 500        |\n",
      "|    ep_rew_mean          | 738        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 685        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 155        |\n",
      "|    total_timesteps      | 106496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01012687 |\n",
      "|    clip_fraction        | 0.0956     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -11.2      |\n",
      "|    explained_variance   | 0.806      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 127        |\n",
      "|    n_updates            | 500        |\n",
      "|    policy_gradient_loss | -0.00769   |\n",
      "|    std                  | 0.986      |\n",
      "|    value_loss           | 1.38e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 862         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 684         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 161         |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004626593 |\n",
      "|    clip_fraction        | 0.0269      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.2       |\n",
      "|    explained_variance   | 0.712       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.89e+03    |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.00403    |\n",
      "|    std                  | 0.986       |\n",
      "|    value_loss           | 1.61e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 924         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 684         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007764727 |\n",
      "|    clip_fraction        | 0.0569      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.2       |\n",
      "|    explained_variance   | 0.811       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.16e+03    |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0075     |\n",
      "|    std                  | 0.981       |\n",
      "|    value_loss           | 1.81e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 938         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 684         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 173         |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009306805 |\n",
      "|    clip_fraction        | 0.0693      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.2       |\n",
      "|    explained_variance   | 0.889       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.69e+03    |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.00755    |\n",
      "|    std                  | 0.985       |\n",
      "|    value_loss           | 7.41e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 1.05e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 683         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008396017 |\n",
      "|    clip_fraction        | 0.0594      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.2       |\n",
      "|    explained_variance   | 0.827       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.29e+03    |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0058     |\n",
      "|    std                  | 0.98        |\n",
      "|    value_loss           | 8.04e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 1.06e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 682          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 186          |\n",
      "|    total_timesteps      | 126976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065525537 |\n",
      "|    clip_fraction        | 0.0406       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -11.2        |\n",
      "|    explained_variance   | 0.829        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.66e+03     |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.00505     |\n",
      "|    std                  | 0.981        |\n",
      "|    value_loss           | 8.74e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 500        |\n",
      "|    ep_rew_mean          | 811        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 682        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 192        |\n",
      "|    total_timesteps      | 131072     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00782688 |\n",
      "|    clip_fraction        | 0.0613     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -11.2      |\n",
      "|    explained_variance   | 0.859      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.78e+03   |\n",
      "|    n_updates            | 620        |\n",
      "|    policy_gradient_loss | -0.00615   |\n",
      "|    std                  | 0.98       |\n",
      "|    value_loss           | 1.72e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 955          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 682          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 198          |\n",
      "|    total_timesteps      | 135168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097189415 |\n",
      "|    clip_fraction        | 0.0925       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -11.2        |\n",
      "|    explained_variance   | 0.82         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 446          |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.00807     |\n",
      "|    std                  | 0.979        |\n",
      "|    value_loss           | 902          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 860          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 680          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 204          |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058539705 |\n",
      "|    clip_fraction        | 0.0337       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -11.1        |\n",
      "|    explained_variance   | 0.876        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 471          |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.00536     |\n",
      "|    std                  | 0.978        |\n",
      "|    value_loss           | 3.14e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 730         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 679         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 210         |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012295224 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.2       |\n",
      "|    explained_variance   | 0.874       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 128         |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.00848    |\n",
      "|    std                  | 0.986       |\n",
      "|    value_loss           | 651         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 726         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 677         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011442654 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.2       |\n",
      "|    explained_variance   | 0.866       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0052     |\n",
      "|    std                  | 0.988       |\n",
      "|    value_loss           | 211         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 748         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 677         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 223         |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007973928 |\n",
      "|    clip_fraction        | 0.0426      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.2       |\n",
      "|    explained_variance   | 0.867       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.00456    |\n",
      "|    std                  | 0.987       |\n",
      "|    value_loss           | 1.33e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 746         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 676         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 229         |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008316594 |\n",
      "|    clip_fraction        | 0.0565      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.2       |\n",
      "|    explained_variance   | 0.826       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 206         |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.00416    |\n",
      "|    std                  | 0.977       |\n",
      "|    value_loss           | 912         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 759          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 676          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 236          |\n",
      "|    total_timesteps      | 159744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048709554 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -11.1        |\n",
      "|    explained_variance   | 0.924        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.05e+03     |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    std                  | 0.97         |\n",
      "|    value_loss           | 3.47e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 666         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 675         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 242         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010175346 |\n",
      "|    clip_fraction        | 0.086       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.1       |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 975         |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.00645    |\n",
      "|    std                  | 0.969       |\n",
      "|    value_loss           | 2.48e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 892          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 674          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 248          |\n",
      "|    total_timesteps      | 167936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048795985 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -11.1        |\n",
      "|    explained_variance   | 0.826        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.76e+03     |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.00501     |\n",
      "|    std                  | 0.966        |\n",
      "|    value_loss           | 1.17e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 860         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 674         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 255         |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004686295 |\n",
      "|    clip_fraction        | 0.0113      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11         |\n",
      "|    explained_variance   | 0.861       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.47e+03    |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.00375    |\n",
      "|    std                  | 0.964       |\n",
      "|    value_loss           | 1.58e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 847         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 674         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 261         |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007881117 |\n",
      "|    clip_fraction        | 0.0561      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11         |\n",
      "|    explained_variance   | 0.789       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 896         |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.006      |\n",
      "|    std                  | 0.965       |\n",
      "|    value_loss           | 6.62e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 852         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 674         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 267         |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010177476 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11         |\n",
      "|    explained_variance   | 0.881       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.00856    |\n",
      "|    std                  | 0.963       |\n",
      "|    value_loss           | 168         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 724         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 674         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 273         |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014473991 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11         |\n",
      "|    explained_variance   | 0.663       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 399         |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.00702    |\n",
      "|    std                  | 0.955       |\n",
      "|    value_loss           | 490         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 696         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 674         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 279         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009844876 |\n",
      "|    clip_fraction        | 0.0806      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11         |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.00465    |\n",
      "|    std                  | 0.961       |\n",
      "|    value_loss           | 361         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 712         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 674         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 285         |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010928211 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11         |\n",
      "|    explained_variance   | 0.826       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 161         |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.00627    |\n",
      "|    std                  | 0.963       |\n",
      "|    value_loss           | 417         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 847         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 673         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 292         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012538203 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11         |\n",
      "|    explained_variance   | 0.841       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 146         |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.00997    |\n",
      "|    std                  | 0.965       |\n",
      "|    value_loss           | 281         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 815         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 672         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 298         |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003949537 |\n",
      "|    clip_fraction        | 0.0078      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11         |\n",
      "|    explained_variance   | 0.716       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.72e+03    |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.00416    |\n",
      "|    std                  | 0.965       |\n",
      "|    value_loss           | 7.79e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 733         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 671         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 304         |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010982275 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11         |\n",
      "|    explained_variance   | 0.871       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.00462    |\n",
      "|    std                  | 0.965       |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 723         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 671         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 311         |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008460237 |\n",
      "|    clip_fraction        | 0.0956      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.1       |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 60.3        |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | -0.00693    |\n",
      "|    std                  | 0.97        |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 645          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 670          |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 317          |\n",
      "|    total_timesteps      | 212992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075860894 |\n",
      "|    clip_fraction        | 0.0306       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -11.1        |\n",
      "|    explained_variance   | 0.806        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.37e+03     |\n",
      "|    n_updates            | 1020         |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    std                  | 0.971        |\n",
      "|    value_loss           | 4.06e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 500        |\n",
      "|    ep_rew_mean          | 539        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 670        |\n",
      "|    iterations           | 53         |\n",
      "|    time_elapsed         | 323        |\n",
      "|    total_timesteps      | 217088     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00803577 |\n",
      "|    clip_fraction        | 0.0547     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -11.1      |\n",
      "|    explained_variance   | 0.712      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 41.4       |\n",
      "|    n_updates            | 1040       |\n",
      "|    policy_gradient_loss | -0.00679   |\n",
      "|    std                  | 0.966      |\n",
      "|    value_loss           | 926        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 493          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 670          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 329          |\n",
      "|    total_timesteps      | 221184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018963118 |\n",
      "|    clip_fraction        | 0.000793     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -11          |\n",
      "|    explained_variance   | 0.822        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.54e+03     |\n",
      "|    n_updates            | 1060         |\n",
      "|    policy_gradient_loss | -0.00265     |\n",
      "|    std                  | 0.965        |\n",
      "|    value_loss           | 6.08e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 518         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 670         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 336         |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012398795 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11         |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 57.4        |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.00857    |\n",
      "|    std                  | 0.962       |\n",
      "|    value_loss           | 182         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 527         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 669         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 342         |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009776626 |\n",
      "|    clip_fraction        | 0.0618      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11         |\n",
      "|    explained_variance   | 0.906       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 502         |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | -0.00649    |\n",
      "|    std                  | 0.962       |\n",
      "|    value_loss           | 687         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 627          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 670          |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 348          |\n",
      "|    total_timesteps      | 233472       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0085853245 |\n",
      "|    clip_fraction        | 0.0606       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -11          |\n",
      "|    explained_variance   | 0.747        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 189          |\n",
      "|    n_updates            | 1120         |\n",
      "|    policy_gradient_loss | -0.00481     |\n",
      "|    std                  | 0.961        |\n",
      "|    value_loss           | 1.35e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 678         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 669         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 354         |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005150831 |\n",
      "|    clip_fraction        | 0.0271      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11         |\n",
      "|    explained_variance   | 0.834       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 436         |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | -0.00519    |\n",
      "|    std                  | 0.96        |\n",
      "|    value_loss           | 3.61e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 800         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 670         |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 360         |\n",
      "|    total_timesteps      | 241664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010204878 |\n",
      "|    clip_fraction        | 0.075       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.9       |\n",
      "|    explained_variance   | 0.89        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 130         |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.00882    |\n",
      "|    std                  | 0.95        |\n",
      "|    value_loss           | 2.6e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 714         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 670         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 366         |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006017686 |\n",
      "|    clip_fraction        | 0.0261      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.9       |\n",
      "|    explained_variance   | 0.78        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.9e+03     |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.00473    |\n",
      "|    std                  | 0.953       |\n",
      "|    value_loss           | 1.03e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 638         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 670         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 372         |\n",
      "|    total_timesteps      | 249856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011462674 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11         |\n",
      "|    explained_variance   | 0.873       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.78        |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | -0.00757    |\n",
      "|    std                  | 0.959       |\n",
      "|    value_loss           | 26.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 680         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 670         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 378         |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009310205 |\n",
      "|    clip_fraction        | 0.0754      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11         |\n",
      "|    explained_variance   | 0.843       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 77.9        |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | -0.00654    |\n",
      "|    std                  | 0.956       |\n",
      "|    value_loss           | 358         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 866         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 670         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 384         |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003376091 |\n",
      "|    clip_fraction        | 0.0079      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11         |\n",
      "|    explained_variance   | 0.862       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.31e+03    |\n",
      "|    n_updates            | 1240        |\n",
      "|    policy_gradient_loss | -0.00507    |\n",
      "|    std                  | 0.956       |\n",
      "|    value_loss           | 5.47e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 831          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 669          |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 391          |\n",
      "|    total_timesteps      | 262144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026160697 |\n",
      "|    clip_fraction        | 0.00211      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -10.9        |\n",
      "|    explained_variance   | 0.695        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.27e+03     |\n",
      "|    n_updates            | 1260         |\n",
      "|    policy_gradient_loss | -0.00233     |\n",
      "|    std                  | 0.955        |\n",
      "|    value_loss           | 1.59e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 780         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 670         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 397         |\n",
      "|    total_timesteps      | 266240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010988577 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.9       |\n",
      "|    explained_variance   | 0.796       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.01        |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.00855    |\n",
      "|    std                  | 0.945       |\n",
      "|    value_loss           | 23.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 787         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 670         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 403         |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001445855 |\n",
      "|    clip_fraction        | 0.000745    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.9       |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 106         |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | -0.00112    |\n",
      "|    std                  | 0.944       |\n",
      "|    value_loss           | 6.36e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 760          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 670          |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 409          |\n",
      "|    total_timesteps      | 274432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076419567 |\n",
      "|    clip_fraction        | 0.0522       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -10.8        |\n",
      "|    explained_variance   | 0.892        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 72.2         |\n",
      "|    n_updates            | 1320         |\n",
      "|    policy_gradient_loss | -0.00446     |\n",
      "|    std                  | 0.94         |\n",
      "|    value_loss           | 6.05e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 840         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 670         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 415         |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006985293 |\n",
      "|    clip_fraction        | 0.0472      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.8       |\n",
      "|    explained_variance   | 0.889       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 77.8        |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.00623    |\n",
      "|    std                  | 0.939       |\n",
      "|    value_loss           | 1.24e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 708          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 670          |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 421          |\n",
      "|    total_timesteps      | 282624       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0081025865 |\n",
      "|    clip_fraction        | 0.0561       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -10.8        |\n",
      "|    explained_variance   | 0.646        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.26e+03     |\n",
      "|    n_updates            | 1360         |\n",
      "|    policy_gradient_loss | -0.00438     |\n",
      "|    std                  | 0.936        |\n",
      "|    value_loss           | 1.98e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 500        |\n",
      "|    ep_rew_mean          | 659        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 670        |\n",
      "|    iterations           | 70         |\n",
      "|    time_elapsed         | 427        |\n",
      "|    total_timesteps      | 286720     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01379562 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.8      |\n",
      "|    explained_variance   | 0.874      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 24.8       |\n",
      "|    n_updates            | 1380       |\n",
      "|    policy_gradient_loss | -0.00664   |\n",
      "|    std                  | 0.941      |\n",
      "|    value_loss           | 101        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 528         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 669         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 434         |\n",
      "|    total_timesteps      | 290816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008551297 |\n",
      "|    clip_fraction        | 0.0778      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.8       |\n",
      "|    explained_variance   | 0.878       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 233         |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | -0.00606    |\n",
      "|    std                  | 0.946       |\n",
      "|    value_loss           | 273         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 606         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 669         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 440         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005975011 |\n",
      "|    clip_fraction        | 0.0378      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.9       |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 794         |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | -0.00569    |\n",
      "|    std                  | 0.943       |\n",
      "|    value_loss           | 1.14e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 733          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 668          |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 447          |\n",
      "|    total_timesteps      | 299008       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039371233 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -10.8        |\n",
      "|    explained_variance   | 0.7          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.13e+03     |\n",
      "|    n_updates            | 1440         |\n",
      "|    policy_gradient_loss | -0.00503     |\n",
      "|    std                  | 0.945        |\n",
      "|    value_loss           | 1.19e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 704          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 668          |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 453          |\n",
      "|    total_timesteps      | 303104       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074897367 |\n",
      "|    clip_fraction        | 0.0333       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -10.9        |\n",
      "|    explained_variance   | 0.878        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.55e+03     |\n",
      "|    n_updates            | 1460         |\n",
      "|    policy_gradient_loss | -0.00602     |\n",
      "|    std                  | 0.945        |\n",
      "|    value_loss           | 2.84e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 644          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 668          |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 459          |\n",
      "|    total_timesteps      | 307200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074661607 |\n",
      "|    clip_fraction        | 0.0387       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -10.8        |\n",
      "|    explained_variance   | 0.937        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.14e+03     |\n",
      "|    n_updates            | 1480         |\n",
      "|    policy_gradient_loss | -0.00584     |\n",
      "|    std                  | 0.938        |\n",
      "|    value_loss           | 3.4e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 570          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 668          |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 465          |\n",
      "|    total_timesteps      | 311296       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097933505 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -10.8        |\n",
      "|    explained_variance   | 0.909        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 36.2         |\n",
      "|    n_updates            | 1500         |\n",
      "|    policy_gradient_loss | -0.00698     |\n",
      "|    std                  | 0.942        |\n",
      "|    value_loss           | 374          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 835         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 668         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 471         |\n",
      "|    total_timesteps      | 315392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004591615 |\n",
      "|    clip_fraction        | 0.0143      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.8       |\n",
      "|    explained_variance   | 0.886       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 719         |\n",
      "|    n_updates            | 1520        |\n",
      "|    policy_gradient_loss | -0.00355    |\n",
      "|    std                  | 0.939       |\n",
      "|    value_loss           | 4.52e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 725          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 668          |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 477          |\n",
      "|    total_timesteps      | 319488       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046478286 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -10.8        |\n",
      "|    explained_variance   | 0.759        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.89e+03     |\n",
      "|    n_updates            | 1540         |\n",
      "|    policy_gradient_loss | -0.00436     |\n",
      "|    std                  | 0.938        |\n",
      "|    value_loss           | 9.81e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 758         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 668         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 484         |\n",
      "|    total_timesteps      | 323584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008932355 |\n",
      "|    clip_fraction        | 0.0667      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.7       |\n",
      "|    explained_variance   | 0.884       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 444         |\n",
      "|    n_updates            | 1560        |\n",
      "|    policy_gradient_loss | -0.00695    |\n",
      "|    std                  | 0.928       |\n",
      "|    value_loss           | 1.3e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 764          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 667          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 490          |\n",
      "|    total_timesteps      | 327680       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0114677455 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -10.7        |\n",
      "|    explained_variance   | 0.903        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 65.4         |\n",
      "|    n_updates            | 1580         |\n",
      "|    policy_gradient_loss | -0.0119      |\n",
      "|    std                  | 0.925        |\n",
      "|    value_loss           | 702          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 735         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 666         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 497         |\n",
      "|    total_timesteps      | 331776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014994284 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.7       |\n",
      "|    explained_variance   | 0.836       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.4        |\n",
      "|    n_updates            | 1600        |\n",
      "|    policy_gradient_loss | -0.0096     |\n",
      "|    std                  | 0.931       |\n",
      "|    value_loss           | 301         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 798         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 665         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 504         |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004419448 |\n",
      "|    clip_fraction        | 0.0142      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.7       |\n",
      "|    explained_variance   | 0.734       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.84e+03    |\n",
      "|    n_updates            | 1620        |\n",
      "|    policy_gradient_loss | -0.00347    |\n",
      "|    std                  | 0.93        |\n",
      "|    value_loss           | 5.8e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 997         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 665         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 511         |\n",
      "|    total_timesteps      | 339968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008628491 |\n",
      "|    clip_fraction        | 0.0648      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.7       |\n",
      "|    explained_variance   | 0.854       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 92.4        |\n",
      "|    n_updates            | 1640        |\n",
      "|    policy_gradient_loss | -0.00641    |\n",
      "|    std                  | 0.934       |\n",
      "|    value_loss           | 974         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 982          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 664          |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 517          |\n",
      "|    total_timesteps      | 344064       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059600463 |\n",
      "|    clip_fraction        | 0.0249       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -10.7        |\n",
      "|    explained_variance   | 0.772        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.65e+03     |\n",
      "|    n_updates            | 1660         |\n",
      "|    policy_gradient_loss | -0.00595     |\n",
      "|    std                  | 0.933        |\n",
      "|    value_loss           | 9.16e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 897         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 664         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 523         |\n",
      "|    total_timesteps      | 348160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007932894 |\n",
      "|    clip_fraction        | 0.0538      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.7       |\n",
      "|    explained_variance   | 0.907       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 594         |\n",
      "|    n_updates            | 1680        |\n",
      "|    policy_gradient_loss | -0.00664    |\n",
      "|    std                  | 0.927       |\n",
      "|    value_loss           | 2.39e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 934          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 664          |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 529          |\n",
      "|    total_timesteps      | 352256       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070391623 |\n",
      "|    clip_fraction        | 0.0504       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -10.7        |\n",
      "|    explained_variance   | 0.915        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 339          |\n",
      "|    n_updates            | 1700         |\n",
      "|    policy_gradient_loss | -0.00595     |\n",
      "|    std                  | 0.924        |\n",
      "|    value_loss           | 1.33e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 998          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 664          |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 536          |\n",
      "|    total_timesteps      | 356352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060637924 |\n",
      "|    clip_fraction        | 0.0413       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -10.6        |\n",
      "|    explained_variance   | 0.909        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.84e+03     |\n",
      "|    n_updates            | 1720         |\n",
      "|    policy_gradient_loss | -0.00475     |\n",
      "|    std                  | 0.918        |\n",
      "|    value_loss           | 2.93e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 1.22e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 664          |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 542          |\n",
      "|    total_timesteps      | 360448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057070088 |\n",
      "|    clip_fraction        | 0.0232       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -10.6        |\n",
      "|    explained_variance   | 0.908        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.09e+03     |\n",
      "|    n_updates            | 1740         |\n",
      "|    policy_gradient_loss | -0.00661     |\n",
      "|    std                  | 0.915        |\n",
      "|    value_loss           | 6.13e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 1.03e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 663         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 549         |\n",
      "|    total_timesteps      | 364544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004599676 |\n",
      "|    clip_fraction        | 0.0164      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.6       |\n",
      "|    explained_variance   | 0.869       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.55e+03    |\n",
      "|    n_updates            | 1760        |\n",
      "|    policy_gradient_loss | -0.0047     |\n",
      "|    std                  | 0.913       |\n",
      "|    value_loss           | 1.38e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 1.08e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 663         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 555         |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008084895 |\n",
      "|    clip_fraction        | 0.0703      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.6       |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 199         |\n",
      "|    n_updates            | 1780        |\n",
      "|    policy_gradient_loss | -0.00644    |\n",
      "|    std                  | 0.915       |\n",
      "|    value_loss           | 1.25e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 1.14e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 663         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 561         |\n",
      "|    total_timesteps      | 372736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009152429 |\n",
      "|    clip_fraction        | 0.0908      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.5       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 178         |\n",
      "|    n_updates            | 1800        |\n",
      "|    policy_gradient_loss | -0.00811    |\n",
      "|    std                  | 0.91        |\n",
      "|    value_loss           | 589         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 1.18e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 663         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 567         |\n",
      "|    total_timesteps      | 376832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008422026 |\n",
      "|    clip_fraction        | 0.0493      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.5       |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 749         |\n",
      "|    n_updates            | 1820        |\n",
      "|    policy_gradient_loss | -0.00749    |\n",
      "|    std                  | 0.906       |\n",
      "|    value_loss           | 2.39e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 1.23e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 663         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 574         |\n",
      "|    total_timesteps      | 380928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007767736 |\n",
      "|    clip_fraction        | 0.0418      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.5       |\n",
      "|    explained_variance   | 0.898       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.16e+03    |\n",
      "|    n_updates            | 1840        |\n",
      "|    policy_gradient_loss | -0.00711    |\n",
      "|    std                  | 0.898       |\n",
      "|    value_loss           | 4.47e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 1.18e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 663          |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 580          |\n",
      "|    total_timesteps      | 385024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068102553 |\n",
      "|    clip_fraction        | 0.0476       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -10.4        |\n",
      "|    explained_variance   | 0.892        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 364          |\n",
      "|    n_updates            | 1860         |\n",
      "|    policy_gradient_loss | -0.00551     |\n",
      "|    std                  | 0.897        |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 1.06e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 663         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 586         |\n",
      "|    total_timesteps      | 389120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009722011 |\n",
      "|    clip_fraction        | 0.0996      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.4       |\n",
      "|    explained_variance   | 0.841       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 118         |\n",
      "|    n_updates            | 1880        |\n",
      "|    policy_gradient_loss | -0.00688    |\n",
      "|    std                  | 0.899       |\n",
      "|    value_loss           | 1.23e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 500        |\n",
      "|    ep_rew_mean          | 1.08e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 663        |\n",
      "|    iterations           | 96         |\n",
      "|    time_elapsed         | 592        |\n",
      "|    total_timesteps      | 393216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00532204 |\n",
      "|    clip_fraction        | 0.0227     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.4      |\n",
      "|    explained_variance   | 0.887      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 676        |\n",
      "|    n_updates            | 1900       |\n",
      "|    policy_gradient_loss | -0.00311   |\n",
      "|    std                  | 0.895      |\n",
      "|    value_loss           | 3.57e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 1.07e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 663          |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 598          |\n",
      "|    total_timesteps      | 397312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060604047 |\n",
      "|    clip_fraction        | 0.0349       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -10.4        |\n",
      "|    explained_variance   | 0.892        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 993          |\n",
      "|    n_updates            | 1920         |\n",
      "|    policy_gradient_loss | -0.00529     |\n",
      "|    std                  | 0.892        |\n",
      "|    value_loss           | 3.19e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 1.12e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 663          |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 605          |\n",
      "|    total_timesteps      | 401408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062171924 |\n",
      "|    clip_fraction        | 0.0314       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -10.4        |\n",
      "|    explained_variance   | 0.938        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 789          |\n",
      "|    n_updates            | 1940         |\n",
      "|    policy_gradient_loss | -0.00397     |\n",
      "|    std                  | 0.889        |\n",
      "|    value_loss           | 3.57e+03     |\n",
      "------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "✓ Training complete! (10.1 minutes)\n",
      "✓ Model saved as 'touch_box_ppo'\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "model_pp = train_pick_place(total_timesteps=400000)  # Train with better approach guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d241b04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ evaluate_model() function defined\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(num_episodes=5, deterministic=True):\n",
    "    \"\"\"Evaluate the model - check how often it touches the box.\"\"\"\n",
    "    from stable_baselines3 import PPO\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"Evaluating Touch Box Model (Improved Control)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    model = PPO.load(\"touch_box_ppo\")\n",
    "    \n",
    "    touches = 0\n",
    "    \n",
    "    for ep in range(num_episodes):\n",
    "        print(f\"\\nEpisode {ep + 1}/{num_episodes}:\")\n",
    "        \n",
    "        env = PickPlaceEnv(model_path='model/pick_place_scene.xml')\n",
    "        obs, _ = env.reset()\n",
    "        box_name = env.active_box\n",
    "        \n",
    "        episode_reward = 0.0\n",
    "        touched = False\n",
    "        \n",
    "        while env.step_count < env.max_episode_steps:\n",
    "            action, _ = model.predict(obs, deterministic=deterministic)\n",
    "            obs, reward, terminated, truncated, _ = env.step(action)\n",
    "            episode_reward += reward\n",
    "            \n",
    "            # Get current distance from obs (indices 0:3 are EE pos, 7:10 are box pos)\n",
    "            ee_pos = obs[:3]\n",
    "            box_pos = obs[7:10]\n",
    "            distance = np.linalg.norm(ee_pos - box_pos)\n",
    "            \n",
    "            if distance < 0.20:  # Increased from 0.15m\n",
    "                touched = True\n",
    "            \n",
    "            if terminated or truncated:\n",
    "                break\n",
    "        \n",
    "        if touched:\n",
    "            touches += 1\n",
    "        \n",
    "        print(f\"  Box: {box_name}\")\n",
    "        print(f\"  Reward: {episode_reward:.2f}\")\n",
    "        print(f\"  Touched: {'✓ YES' if touched else '✗ NO'}\")\n",
    "        \n",
    "        env.close()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"Success Rate: {touches}/{num_episodes} ({100*touches/num_episodes:.0f}%)\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "print(\"✓ evaluate_model() function defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b0a4403d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Evaluating Touch Box Model (Improved Control)\n",
      "======================================================================\n",
      "\n",
      "Episode 1/10:\n",
      "  Box: green_box_2\n",
      "  Reward: -3.90\n",
      "  Touched: ✓ YES\n",
      "\n",
      "Episode 2/10:\n",
      "  Box: yellow_box_1\n",
      "  Reward: 7355.56\n",
      "  Touched: ✓ YES\n",
      "\n",
      "Episode 3/10:\n",
      "  Box: green_box_1\n",
      "  Reward: -3.66\n",
      "  Touched: ✗ NO\n",
      "\n",
      "Episode 4/10:\n",
      "  Box: yellow_box_0\n",
      "  Reward: 8343.60\n",
      "  Touched: ✓ YES\n",
      "\n",
      "Episode 5/10:\n",
      "  Box: yellow_box_0\n",
      "  Reward: 8343.60\n",
      "  Touched: ✓ YES\n",
      "\n",
      "Episode 6/10:\n",
      "  Box: blue_box_0\n",
      "  Reward: -3.95\n",
      "  Touched: ✗ NO\n",
      "\n",
      "Episode 7/10:\n",
      "  Box: red_box_0\n",
      "  Reward: -3.86\n",
      "  Touched: ✗ NO\n",
      "\n",
      "Episode 8/10:\n",
      "  Box: blue_box_1\n",
      "  Reward: -3.89\n",
      "  Touched: ✗ NO\n",
      "\n",
      "Episode 9/10:\n",
      "  Box: yellow_box_1\n",
      "  Reward: 7355.56\n",
      "  Touched: ✓ YES\n",
      "\n",
      "Episode 10/10:\n",
      "  Box: red_box_1\n",
      "  Reward: -3.78\n",
      "  Touched: ✗ NO\n",
      "\n",
      "======================================================================\n",
      "Success Rate: 5/10 (50%)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(num_episodes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b809ec74",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Current Task**: Train Franka Panda arm to touch a randomly-placed box\n",
    "- Single box per episode (randomly selected from 12 available)\n",
    "- Dense reaching reward: 50.0 × (1 - distance/0.8)\n",
    "- Touch bonus: +100.0 when distance < 0.15m\n",
    "- Time penalty: -0.001 per step\n",
    "- 500 steps per episode\n",
    "- Observation: 22D (arm state + gripper + end-effector + box position)\n",
    "- Action: 8D continuous (7 arm joints + 1 gripper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9241e9e",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4ac5b024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ visualize_model() function defined\n"
     ]
    }
   ],
   "source": [
    "def visualize_model(num_episodes=3, deterministic=True):\n",
    "    \"\"\"Visualize the trained model.\"\"\"\n",
    "    from stable_baselines3 import PPO\n",
    "    import mujoco.viewer\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"Visualizing Touch Box Model\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Episodes: {num_episodes}\\n\")\n",
    "    \n",
    "    model = PPO.load(\"touch_box_ppo\")\n",
    "    \n",
    "    for ep in range(num_episodes):\n",
    "        print(f\"Episode {ep + 1}/{num_episodes}\")\n",
    "        \n",
    "        env = PickPlaceEnv(model_path='model/pick_place_scene.xml')\n",
    "        obs, _ = env.reset()\n",
    "        \n",
    "        viewer = mujoco.viewer.launch_passive(env.model, env.data)\n",
    "        \n",
    "        try:\n",
    "            while env.step_count < env.max_episode_steps:\n",
    "                action, _ = model.predict(obs, deterministic=deterministic)\n",
    "                obs, reward, terminated, truncated, _ = env.step(action)\n",
    "                \n",
    "                if terminated or truncated:\n",
    "                    break\n",
    "                \n",
    "                viewer.sync()\n",
    "                \n",
    "        finally:\n",
    "            viewer.close()\n",
    "            env.close()\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"Done!\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "print(\"✓ visualize_model() function defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "08463dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Visualizing Touch Box Model\n",
      "======================================================================\n",
      "Episodes: 5\n",
      "\n",
      "Episode 1/5\n",
      "Episode 2/5\n",
      "Episode 3/5\n",
      "Episode 4/5\n",
      "Episode 5/5\n",
      "======================================================================\n",
      "Done!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "visualize_model(num_episodes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5324472f",
   "metadata": {},
   "source": [
    "## Debugging and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "00f46d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ debug_environment() function defined\n"
     ]
    }
   ],
   "source": [
    "def debug_environment():\n",
    "    \"\"\"Debug the environment to understand observations and actions (improved control).\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"Environment Debugging Information\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    env = PickPlaceEnv(model_path='model/pick_place_scene.xml')\n",
    "    obs, _ = env.reset()\n",
    "    \n",
    "    print(f\"\\n✓ Environment initialized successfully (panda-gym style)\")\n",
    "    print(f\"  Model: Franka Panda with parallel gripper\")\n",
    "    print(f\"  Action space: {env.action_space.shape} (7 arm joints + 1 gripper)\")\n",
    "    print(f\"  Observation space: {env.observation_space.shape} (simplified)\")\n",
    "    \n",
    "    print(f\"\\nObservation breakdown (10D total):\")\n",
    "    print(f\"  [0:3]    = End-effector (hand) position (m)\")\n",
    "    print(f\"  [3:6]    = End-effector velocity (m/s)\")\n",
    "    print(f\"  [6]      = Gripper width (m, 0 to 0.04)\")\n",
    "    print(f\"  [7:10]   = Target box position (m)\")\n",
    "    \n",
    "    print(f\"\\nInitial observation sample:\")\n",
    "    print(f\"  EE position: {obs[:3]}\")\n",
    "    print(f\"  EE velocity: {obs[3:6]}\")\n",
    "    print(f\"  Gripper width: {obs[6]:.4f}\")\n",
    "    print(f\"  Box position: {obs[7:10]}\")\n",
    "    \n",
    "    # Test an action with incremental control\n",
    "    action = np.zeros(8)\n",
    "    action[0] = 0.5   # Move joint 1 (incremental, 0.025 rad max)\n",
    "    action[7] = -0.5  # Close gripper (incremental, 0.025m max)\n",
    "    \n",
    "    print(f\"\\nTest action (move joint 1 incrementally, close gripper):\")\n",
    "    print(f\"  Action: {action}\")\n",
    "    print(f\"  Max step: 0.05 rad/step for arm, 0.05m/step for gripper\")\n",
    "    \n",
    "    obs, reward, terminated, truncated, _ = env.step(action)\n",
    "    print(f\"  Reward: {reward:.4f}\")\n",
    "    print(f\"  New EE position: {obs[:3]}\")\n",
    "    print(f\"  New gripper width: {obs[6]:.4f}\")\n",
    "    \n",
    "    print(f\"\\n\" + \"=\" * 70)\n",
    "    print(\"✓ Environment is working correctly!\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    env.close()\n",
    "\n",
    "print(\"✓ debug_environment() function defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "778ca394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Environment Debugging Information\n",
      "======================================================================\n",
      "\n",
      "✓ Environment initialized successfully (panda-gym style)\n",
      "  Model: Franka Panda with parallel gripper\n",
      "  Action space: (8,) (7 arm joints + 1 gripper)\n",
      "  Observation space: (10,) (simplified)\n",
      "\n",
      "Observation breakdown (10D total):\n",
      "  [0:3]    = End-effector (hand) position (m)\n",
      "  [3:6]    = End-effector velocity (m/s)\n",
      "  [6]      = Gripper width (m, 0 to 0.04)\n",
      "  [7:10]   = Target box position (m)\n",
      "\n",
      "Initial observation sample:\n",
      "  EE position: [ 6.3968778e-01 -5.0722992e-06  3.0501890e-01]\n",
      "  EE velocity: [-0.00484349 -0.04825507  0.42023802]\n",
      "  Gripper width: 0.0746\n",
      "  Box position: [-0.3       -0.1        0.0482342]\n",
      "\n",
      "Test action (move joint 1 incrementally, close gripper):\n",
      "  Action: [ 0.5  0.   0.   0.   0.   0.   0.  -0.5]\n",
      "  Max step: 0.05 rad/step for arm, 0.05m/step for gripper\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (7,) (3,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[102]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdebug_environment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[100]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mdebug_environment\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Action: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maction\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Max step: 0.05 rad/step for arm, 0.05m/step for gripper\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m obs, reward, terminated, truncated, _ = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Reward: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreward\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  New EE position: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobs[:\u001b[32m3\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[99]\u001b[39m\u001b[32m, line 137\u001b[39m, in \u001b[36mPickPlaceEnv.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    133\u001b[39m     desired_vel = desired_vel * max_vel\n\u001b[32m    135\u001b[39m     \u001b[38;5;66;03m# Convert desired cartesian velocity to joint velocity (simplified)\u001b[39;00m\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# Just use scaled action toward target\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     arm_ctrl = (\u001b[43maction\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m7\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msign\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos_error\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.5\u001b[39;49m) * \u001b[38;5;28mself\u001b[39m.max_action_step * \u001b[32m0.4\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    139\u001b[39m     \u001b[38;5;66;03m# Close to target, execute finer control\u001b[39;00m\n\u001b[32m    140\u001b[39m     arm_ctrl = action[:\u001b[32m7\u001b[39m] * \u001b[38;5;28mself\u001b[39m.max_action_step * \u001b[32m0.2\u001b[39m  \u001b[38;5;66;03m# Very slow fine motion\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: operands could not be broadcast together with shapes (7,) (3,) "
     ]
    }
   ],
   "source": [
    "debug_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ab72eeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Space Test\n",
      "==================================================\n",
      "Observation shape: (10,) (expected (10,))\n",
      "Observation dtype: float32\n",
      "\n",
      "Observation values:\n",
      "  EE position (obs[0:3]): [ 6.3968778e-01 -5.0722992e-06  3.0501890e-01]\n",
      "  EE velocity (obs[3:6]): [-0.00484349 -0.04825507  0.42023802]\n",
      "  Gripper width (obs[6]): 0.0746\n",
      "  Box position (obs[7:10]): [ 0.2       -0.1        0.0482342]\n",
      "\n",
      "Active box: yellow_box_0\n",
      "\n",
      "After action:\n",
      "  EE position changed: [0.6392     0.00309535 0.3079832 ]\n",
      "  Gripper width changed: 0.0649\n",
      "\n",
      "✓ Observation format is correct!\n"
     ]
    }
   ],
   "source": [
    "# Quick test to verify new observation format\n",
    "env = PickPlaceEnv(model_path='model/pick_place_scene.xml')\n",
    "obs, _ = env.reset()\n",
    "\n",
    "print(\"Observation Space Test\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Observation shape: {obs.shape} (expected (10,))\")\n",
    "print(f\"Observation dtype: {obs.dtype}\")\n",
    "print(f\"\\nObservation values:\")\n",
    "print(f\"  EE position (obs[0:3]): {obs[:3]}\")\n",
    "print(f\"  EE velocity (obs[3:6]): {obs[3:6]}\")\n",
    "print(f\"  Gripper width (obs[6]): {obs[6]:.4f}\")\n",
    "print(f\"  Box position (obs[7:10]): {obs[7:10]}\")\n",
    "print(f\"\\nActive box: {env.active_box}\")\n",
    "\n",
    "# Test an action\n",
    "action = np.array([0.1, 0, 0, 0, 0, 0, 0, -0.5])  # Move joint 1, close gripper\n",
    "obs_new, reward, terminated, truncated, _ = env.step(action)\n",
    "print(f\"\\nAfter action:\")\n",
    "print(f\"  EE position changed: {obs_new[:3]}\")\n",
    "print(f\"  Gripper width changed: {obs_new[6]:.4f}\")\n",
    "\n",
    "env.close()\n",
    "print(\"\\n✓ Observation format is correct!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "629b5b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance Analysis\n",
      "======================================================================\n",
      "Episode 1: min distance = 0.3079m\n",
      "Episode 2: min distance = 0.1059m\n",
      "Episode 3: min distance = 0.1790m\n",
      "Episode 4: min distance = 0.5485m\n",
      "Episode 5: min distance = 0.6006m\n",
      "Episode 6: min distance = 0.2932m\n",
      "Episode 7: min distance = 0.7031m\n",
      "Episode 8: min distance = 0.1501m\n",
      "Episode 9: min distance = 0.7666m\n",
      "Episode 10: min distance = 0.5485m\n",
      "\n",
      "======================================================================\n",
      "Minimum distance statistics:\n",
      "  Mean: 0.4203m\n",
      "  Std: 0.2289m\n",
      "  Min: 0.1059m\n",
      "  Max: 0.7666m\n",
      "\n",
      "Current touch threshold: 0.15m\n",
      "Episodes below 0.15m: 1/10\n",
      "Episodes below 0.20m: 3/10\n",
      "Episodes below 0.25m: 3/10\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "def analyze_distances():\n",
    "    \"\"\"Analyze minimum distances achieved during episodes.\"\"\"\n",
    "    from stable_baselines3 import PPO\n",
    "    \n",
    "    try:\n",
    "        model = PPO.load(\"touch_box_ppo\")\n",
    "    except:\n",
    "        print(\"Model not found. Train first with: train_pick_place()\")\n",
    "        return\n",
    "    \n",
    "    print(\"Distance Analysis\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    min_distances = []\n",
    "    \n",
    "    for ep in range(10):\n",
    "        env = PickPlaceEnv(model_path='model/pick_place_scene.xml')\n",
    "        obs, _ = env.reset()\n",
    "        \n",
    "        ep_min_distance = float('inf')\n",
    "        \n",
    "        while env.step_count < env.max_episode_steps:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, _, terminated, truncated, _ = env.step(action)\n",
    "            \n",
    "            ee_pos = obs[:3]\n",
    "            box_pos = obs[7:10]\n",
    "            distance = np.linalg.norm(ee_pos - box_pos)\n",
    "            \n",
    "            ep_min_distance = min(ep_min_distance, distance)\n",
    "            \n",
    "            if terminated or truncated:\n",
    "                break\n",
    "        \n",
    "        min_distances.append(ep_min_distance)\n",
    "        print(f\"Episode {ep + 1}: min distance = {ep_min_distance:.4f}m\")\n",
    "        env.close()\n",
    "    \n",
    "    min_distances = np.array(min_distances)\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"Minimum distance statistics:\")\n",
    "    print(f\"  Mean: {min_distances.mean():.4f}m\")\n",
    "    print(f\"  Std: {min_distances.std():.4f}m\")\n",
    "    print(f\"  Min: {min_distances.min():.4f}m\")\n",
    "    print(f\"  Max: {min_distances.max():.4f}m\")\n",
    "    print(f\"\\nCurrent touch threshold: 0.15m\")\n",
    "    print(f\"Episodes below 0.15m: {(min_distances < 0.15).sum()}/10\")\n",
    "    print(f\"Episodes below 0.20m: {(min_distances < 0.20).sum()}/10\")\n",
    "    print(f\"Episodes below 0.25m: {(min_distances < 0.25).sum()}/10\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "analyze_distances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4720704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: nq=93, nu=8, nv=81\n",
      "Debug: ctrl shape=(8,)\n",
      "Debug: qpos shape=(93,)\n",
      "Policy Action Inspection\n",
      "======================================================================\n",
      "Step 0: gripper_action=1.000, gripper_control=255, is_closed=False\n",
      "Step 1: gripper_action=1.000, gripper_control=255, is_closed=False\n",
      "Step 2: gripper_action=1.000, gripper_control=255, is_closed=False\n",
      "Step 3: gripper_action=1.000, gripper_control=255, is_closed=False\n",
      "Step 4: gripper_action=1.000, gripper_control=255, is_closed=False\n",
      "Step 5: gripper_action=1.000, gripper_control=255, is_closed=False\n",
      "Step 6: gripper_action=1.000, gripper_control=255, is_closed=False\n",
      "Step 7: gripper_action=1.000, gripper_control=255, is_closed=False\n",
      "Step 8: gripper_action=1.000, gripper_control=255, is_closed=False\n",
      "Step 9: gripper_action=1.000, gripper_control=255, is_closed=False\n",
      "Step 20: gripper_action=-0.400, gripper_control=76, is_closed=False\n",
      "Step 40: gripper_action=0.410, gripper_control=179, is_closed=False\n",
      "Step 60: gripper_action=0.401, gripper_control=178, is_closed=False\n",
      "Step 80: gripper_action=1.000, gripper_control=255, is_closed=False\n",
      "\n",
      "======================================================================\n",
      "Gripper Action Statistics:\n",
      "  Mean: 0.296\n",
      "  Std: 0.800\n",
      "  Min: -1.000\n",
      "  Max: 1.000\n",
      "  % below -0.5 (closing): 23.0%\n",
      "  % above +0.5 (opening): 56.0%\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "def inspect_policy_actions():\n",
    "    \"\"\"Inspect what actions the trained policy produces (for debugging).\"\"\"\n",
    "    from stable_baselines3 import PPO\n",
    "    \n",
    "    try:\n",
    "        model = PPO.load(\"touch_box_ppo\")\n",
    "    except:\n",
    "        print(\"Model not found. Train first with: train_pick_place()\")\n",
    "        return\n",
    "    \n",
    "    env = PickPlaceEnv(model_path='model/pick_place_scene.xml')\n",
    "    obs, _ = env.reset()\n",
    "    \n",
    "    print(\"Policy Action Analysis\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    gripper_actions = []\n",
    "    arm_joint_actions = []\n",
    "    distances = []\n",
    "    \n",
    "    for i in range(100):\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, _, _, _ = env.step(action)\n",
    "        \n",
    "        gripper_actions.append(action[7])\n",
    "        arm_joint_actions.append(np.mean(np.abs(action[:7])))  # Mean absolute arm movement\n",
    "        \n",
    "        # Extract distance from observation (obs[0:3] is EE, obs[7:10] is box)\n",
    "        ee_pos = obs[:3]\n",
    "        box_pos = obs[7:10]\n",
    "        distance = np.linalg.norm(ee_pos - box_pos)\n",
    "        distances.append(distance)\n",
    "    \n",
    "    gripper_actions = np.array(gripper_actions)\n",
    "    arm_actions = np.array(arm_joint_actions)\n",
    "    distances = np.array(distances)\n",
    "    \n",
    "    print(\"Gripper Action Statistics:\")\n",
    "    print(f\"  Mean: {gripper_actions.mean():.3f}\")\n",
    "    print(f\"  Std: {gripper_actions.std():.3f}\")\n",
    "    print(f\"  Min: {gripper_actions.min():.3f}\")\n",
    "    print(f\"  Max: {gripper_actions.max():.3f}\")\n",
    "    print(f\"  % closing (< -0.1): {100 * (gripper_actions < -0.1).mean():.1f}%\")\n",
    "    print(f\"  % opening (> +0.1): {100 * (gripper_actions > 0.1).mean():.1f}%\")\n",
    "    print()\n",
    "    print(\"Arm Movement Statistics:\")\n",
    "    print(f\"  Mean absolute movement: {arm_actions.mean():.3f}\")\n",
    "    print(f\"  Max movement: {arm_actions.max():.3f}\")\n",
    "    print()\n",
    "    print(\"Distance to Box:\")\n",
    "    print(f\"  Initial: {distances[0]:.3f}m\")\n",
    "    print(f\"  Final: {distances[-1]:.3f}m\")\n",
    "    print(f\"  Min: {distances.min():.3f}m\")\n",
    "    print(f\"  Mean: {distances.mean():.3f}m\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    env.close()\n",
    "\n",
    "inspect_policy_actions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731c57d1",
   "metadata": {},
   "source": [
    "## Visualize the Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af2a94dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the empty scene without training\n",
    "import mujoco.viewer\n",
    "\n",
    "model_path = 'model/pick_place_scene.xml'\n",
    "model = mujoco.MjModel.from_xml_path(model_path)\n",
    "data = mujoco.MjData(model)\n",
    "\n",
    "# Run simulation for a few seconds to see the scene\n",
    "with mujoco.viewer.launch_passive(model, data) as viewer:\n",
    "    # Run for 2 seconds\n",
    "    start = time.time()\n",
    "    while viewer.is_running() and time.time() - start < 10.0:\n",
    "        step_start = data.time\n",
    "        while (data.time - step_start) < model.opt.timestep * 10:\n",
    "            mujoco.mj_step(model, data)\n",
    "        \n",
    "        viewer.sync()\n",
    "        time.sleep(0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
